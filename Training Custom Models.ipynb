{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7edf78a8",
      "metadata": {
        "id": "7edf78a8"
      },
      "source": [
        "###### DISCLAIMER: This homework was done on Google collab with permission from the instructor, to utilize the T4 GPU from Google, along with CUDA. However, let it be known that Google collab has an auto fill feature (similar to that of Gmail autofill or on Google docs where it finishes sentences for you), which could autofill the code. I wasn't able to find the setting to turn it off, however, I tried my best to adhere to the academic honesty policies. Wherever autofill was used, I have cited it, but also primarily because it made sense to do the code that way. However, all points of academic honesty was honored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5e544da5",
      "metadata": {
        "id": "5e544da5"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "iumAkJ_xN4bR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "iumAkJ_xN4bR",
        "outputId": "a9f4169d-a078-4a4b-b3ed-ed06dbfe7dbc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d332c2f8-adcc-4e4b-9f33-f954aa4cd012\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d332c2f8-adcc-4e4b-9f33-f954aa4cd012\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving covid19_ultrasound.zip to covid19_ultrasound.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "import zipfile\n",
        "import os\n",
        "zip_path = \"covid19_ultrasound.zip\"\n",
        "extract_path = \"covid19_ultrasound\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall (extract_path)\n",
        "\n",
        "#reference: https://stackoverflow.com/questions/49685924/extract-google-drive-zip-from-google-colab-notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fea53ba8",
      "metadata": {
        "id": "fea53ba8"
      },
      "outputs": [],
      "source": [
        "## hyperparameters\n",
        "learning_rate = 1e-5\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "hidden_size = 64\n",
        "dropout = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c1a88704",
      "metadata": {
        "id": "c1a88704"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "43438f77",
      "metadata": {
        "id": "43438f77"
      },
      "outputs": [],
      "source": [
        "class CovidUltrasoundDataset(Dataset):\n",
        "    def __init__(self, part):\n",
        "        self.part = part  # [\"train\", \"val\", \"test\"]\n",
        "        self.DATA_DIR = \"./covid19_ultrasound/\"\n",
        "        # choose folders for val and test set\n",
        "        self.val_fold = 3\n",
        "        self.test_fold = 4\n",
        "        self.IMG_WIDTH, self.IMG_HEIGHT = img_width, img_height\n",
        "        print('Loading images...')\n",
        "        imagePaths = [] #FILL ME\n",
        "        self.label_dict = {\"regular\": 0, \"pneumonia\": 1, \"covid\": 2}\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "#reference: https://www.geeksforgeeks.org/python-os-listdir-method/\n",
        "        temp = os.listdir(self.DATA_DIR) # all stuff in dataset\n",
        "        for counter in temp: #Process each item in the dataset\n",
        "            folder_path = os.path.join(self.DATA_DIR, counter) # Construct full path to the current item\n",
        "            if not os.path.isdir(folder_path):\n",
        "                continue # Skip non-directory items (files, symlinks, etc.)\n",
        "            try:\n",
        "                fold_num = int(counter[-1]) # Convert last char to int\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "\n",
        "            include = False\n",
        "            if self.part == 'train' and fold_num in [0, 1, 2]:\n",
        "                include = True #Training sets for 0-2\n",
        "            elif self.part == 'val' and fold_num == self.val_fold:\n",
        "                include = True #Validation sets 3\n",
        "            elif self.part == 'test' and fold_num == self.test_fold:\n",
        "                include = True #test sets 4\n",
        "            if include:\n",
        "                for cls in self.label_dict.keys(): # Construct path pattern\\/\n",
        "                    cls_path = os.path.join(folder_path, cls, '*')\n",
        "                    imagePaths.extend(glob.glob(cls_path))\n",
        "\n",
        "        for imagePath in imagePaths:\n",
        "            path_parts = imagePath.split(os.path.sep)\n",
        "            # extract the split\n",
        "            train_test = path_parts[-3][-1]\n",
        "            # extract the class label from the filename\n",
        "            label = path_parts[-2]\n",
        "            # load the image, swap color channels, and resize it to be a fixed\n",
        "            # 224x224 pixels while ignoring aspect ratio\n",
        "            image = Image.open(imagePath).convert('RGB')\n",
        "            image = transform(image)\n",
        "            # update the data and labels lists, respectively\n",
        "            # FILL ME\n",
        "            self.data.append(image)\n",
        "            self.labels.append(self.label_dict[label])\n",
        "            #image.close() ##I HAD TO DELETE THIS PORTION OR MY CODE BREAKS\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) #FILL ME\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx] #FILL ME\n",
        "\n",
        "#Additional references used in this section:\n",
        "#reference: https://www.geeksforgeeks.org/python-os-path-join-method/\n",
        "#reference: https://github.com/learnables/learn2learn/blob/master/learn2learn/vision/datasets/describable_textures.py\n",
        "#reference: https://docs.python.org/3/library/glob.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d28b5539",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d28b5539",
        "outputId": "2d42d034-75b3-40c1-b8f9-269017bdafbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading images...\n",
            "Loading images...\n",
            "Loading images...\n"
          ]
        }
      ],
      "source": [
        "trainset = CovidUltrasoundDataset(\"train\")\n",
        "valset = CovidUltrasoundDataset(\"val\")\n",
        "testset = CovidUltrasoundDataset(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9e9519a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e9519a7",
        "outputId": "0b6ca5fe-26df-4560-bb5b-9edd30b19a0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1424"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1ec50d85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ec50d85",
        "outputId": "bd773394-117c-4132-cf41-9093b019dd68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_, label = trainset[28]\n",
        "image_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4584c6ac",
      "metadata": {
        "id": "4584c6ac"
      },
      "outputs": [],
      "source": [
        "# Dataloader\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#references: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "#references: https://machinelearningmastery.com/training-a-pytorch-model-with-dataloader-and-dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3d63aee7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d63aee7",
        "outputId": "584e46a1-c99f-4ae5-ffca-3a2cb8629f35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# construct model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size=(3, 224, 224), hidden_size=64, dropout=0.5,\n",
        "                 num_classes=3):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # load the VGG16 network, ensuring the head layer sets are left off\n",
        "        self.baseModel = models.vgg16(pretrained=False)\n",
        "\n",
        "        # construct the head of the model that will be placed on top of the base model\n",
        "        self.head = nn.Sequential(nn.AdaptiveAvgPool2d((7, 7)),nn.Flatten(),nn.Linear(512*7*7, hidden_size),nn.BatchNorm1d(hidden_size),nn.ReLU(),nn.Dropout(dropout),nn.Linear(hidden_size, num_classes),nn.Softmax(dim=1))\n",
        "        # b-i, ii, iii, iv, v, vi, vii, viii MUST BE IN ORDER\n",
        "        #reference: https://github.com/KeremTurgutlu/self_supervised/blob/main/nbs/02%20-%20layers.ipynb\n",
        "    def forward(self, x):\n",
        "        x = nn.Sequential(*list(self.baseModel.features[:21]))(x)\n",
        "        print(x.shape)\n",
        "        # construct the head of the model on top of the base model to complete computational graph\n",
        "        x = self.head(x) #FILL ME\n",
        "        return x\n",
        "\n",
        "net = Model(hidden_size=hidden_size, dropout=dropout, num_classes=3)\n",
        " #reference: https://github.com/mint-lab/dl_tutorial/blob/master/examples/cnn_mnist_class_style.py\n",
        " #reference: https://github.com/pytorch/tutorials/blob/main/beginner_source/basics/buildmodel_tutorial.py\n",
        " #reference: https://www.geeksforgeeks.org/computational-graph-in-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3d5e8501",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d5e8501",
        "outputId": "17e004d4-2bb3-4ca5-9ef6-5d425c3f0c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "torch.Size([32, 512, 28, 28])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model                                    [32, 3]                   --\n",
              "├─VGG: 1-1                               --                        123,642,856\n",
              "│    └─Sequential: 2-1                   --                        9,439,232\n",
              "│    │    └─Conv2d: 3-1                  [32, 64, 224, 224]        1,792\n",
              "│    │    └─ReLU: 3-2                    [32, 64, 224, 224]        --\n",
              "│    │    └─Conv2d: 3-3                  [32, 64, 224, 224]        36,928\n",
              "│    │    └─ReLU: 3-4                    [32, 64, 224, 224]        --\n",
              "│    │    └─MaxPool2d: 3-5               [32, 64, 112, 112]        --\n",
              "│    │    └─Conv2d: 3-6                  [32, 128, 112, 112]       73,856\n",
              "│    │    └─ReLU: 3-7                    [32, 128, 112, 112]       --\n",
              "│    │    └─Conv2d: 3-8                  [32, 128, 112, 112]       147,584\n",
              "│    │    └─ReLU: 3-9                    [32, 128, 112, 112]       --\n",
              "│    │    └─MaxPool2d: 3-10              [32, 128, 56, 56]         --\n",
              "│    │    └─Conv2d: 3-11                 [32, 256, 56, 56]         295,168\n",
              "│    │    └─ReLU: 3-12                   [32, 256, 56, 56]         --\n",
              "│    │    └─Conv2d: 3-13                 [32, 256, 56, 56]         590,080\n",
              "│    │    └─ReLU: 3-14                   [32, 256, 56, 56]         --\n",
              "│    │    └─Conv2d: 3-15                 [32, 256, 56, 56]         590,080\n",
              "│    │    └─ReLU: 3-16                   [32, 256, 56, 56]         --\n",
              "│    │    └─MaxPool2d: 3-17              [32, 256, 28, 28]         --\n",
              "│    │    └─Conv2d: 3-18                 [32, 512, 28, 28]         1,180,160\n",
              "│    │    └─ReLU: 3-19                   [32, 512, 28, 28]         --\n",
              "│    │    └─Conv2d: 3-20                 [32, 512, 28, 28]         2,359,808\n",
              "│    │    └─ReLU: 3-21                   [32, 512, 28, 28]         --\n",
              "├─Sequential: 1-2                        [32, 3]                   --\n",
              "│    └─AdaptiveAvgPool2d: 2-2            [32, 512, 7, 7]           --\n",
              "│    └─Flatten: 2-3                      [32, 25088]               --\n",
              "│    └─Linear: 2-4                       [32, 64]                  1,605,696\n",
              "│    └─BatchNorm1d: 2-5                  [32, 64]                  128\n",
              "│    └─ReLU: 2-6                         [32, 64]                  --\n",
              "│    └─Dropout: 2-7                      [32, 64]                  --\n",
              "│    └─Linear: 2-8                       [32, 3]                   195\n",
              "│    └─Softmax: 2-9                      [32, 3]                   --\n",
              "==========================================================================================\n",
              "Total params: 139,963,563\n",
              "Trainable params: 139,963,563\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 387.97\n",
              "==========================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 3288.37\n",
              "Params size (MB): 27.53\n",
              "Estimated Total Size (MB): 3335.16\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "summary(net, input_size=(32, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0d3106ee",
      "metadata": {
        "id": "0d3106ee"
      },
      "outputs": [],
      "source": [
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4d9d3333",
      "metadata": {
        "id": "4d9d3333"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(trainloader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    for i, data in enumerate(trainloader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        #FILL ME\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print or record loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    return model, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a09f0a71",
      "metadata": {
        "id": "a09f0a71"
      },
      "outputs": [],
      "source": [
        "def eval_one_epoch(evalloader, model, loss_fn):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data in evalloader:\n",
        "            images, labels = data\n",
        "            # move the data to GPU\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            #FILL ME\n",
        "            _, predicted = torch.max(outputs.data, 1) #THIS WAS THE ONLY LINE THAT GCOLLAB SUGGESTED I ADD OR ELSE MY CODE BREAKS\n",
        "            #I researched this code and here's my reference: https://community.wandb.ai/t/how-use-metrics-with-pytorch/6370\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return running_loss/total, correct/total\n",
        "#reference: https://gist.github.com/GeorgeSeif/07a7707976a163cfaa94218db45a0046\n",
        "#reference: https://github.com/ebagdasa/pytorch-privacy/blob/master/training.py\n",
        "#reference: https://discuss.pytorch.org/t/can-anyone-check-my-mistake-and-explain-me-how-to-correct-the-error/48131"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d52e90f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1d52e90f",
        "outputId": "4253e52b-bfa0-4961-a468-59e885e5ac65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 1 Validation Accuracy: 0.8340486409155937\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 2 Validation Accuracy: 0.8655221745350501\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 3 Validation Accuracy: 0.8927038626609443\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 4 Validation Accuracy: 0.8569384835479256\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 5 Validation Accuracy: 0.8011444921316166\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 6 Validation Accuracy: 0.8383404864091559\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 7 Validation Accuracy: 0.8054363376251789\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 8 Validation Accuracy: 0.7911301859799714\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 9 Validation Accuracy: 0.7610872675250357\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 10 Validation Accuracy: 0.7238912732474965\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([28, 512, 28, 28])\n",
            "\n",
            "Final Test Accuracy: 0.7694610778443114\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([28, 512, 28, 28])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Confusion Matrix')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#PART C:    Implement early stopping. One way is to complete training through a\n",
        "            #preset number of epochs and design a criterion to choose the best epoch (suffering\n",
        "            #the least from overfitting).\n",
        "\n",
        "#references: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
        "# Training with early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "no_improve = 0\n",
        "val_loss_history = []\n",
        "\n",
        "# training and validation\n",
        "for epoch in range(epochs):\n",
        "    net, optimizer = train_one_epoch(trainloader, net, criterion, optimizer)\n",
        "    val_loss, val_acc = eval_one_epoch(valloader, net, criterion)\n",
        "    val_loss_history.append(val_acc)\n",
        "\n",
        "    print('Epoch:', epoch+1, 'Validation Accuracy:', val_acc)\n",
        "    if val_acc < best_val_loss:\n",
        "        best_val_loss = val_acc\n",
        "        torch.save(net.state_dict(), 'best_model.pth')\n",
        "        no_improve = 0\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        if no_improve >= patience:\n",
        "            print('Early stopping at epoch: ',epoch+1)\n",
        "            break\n",
        "\n",
        "\n",
        "#PART D:    Evaluation. Evaluate the model obtained at the best epoch in c). Test the\n",
        "            #accuracy and plot the confusion matrix on the test set.\n",
        "\n",
        "net.load_state_dict(torch.load('best_model.pth'))\n",
        "test_loss, test_acc = eval_one_epoch(testloader, net, criterion)\n",
        "print('\\nFinal Test Accuracy:', test_acc)\n",
        "\n",
        "# Confusion Matrix\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "net.eval()\n",
        "#reference: https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad\n",
        "#reference: https://pytorch.org/docs/stable/notes/cuda.html\n",
        "with torch.no_grad():\n",
        "    preds_list = []\n",
        "    labels_list = []\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        preds_list.append(outputs.argmax(dim=1))# Store tensors directly\n",
        "        labels_list.append(labels)\n",
        "    all_preds = torch.cat(preds_list).cpu().numpy()\n",
        "    all_labels = torch.cat(labels_list).cpu().numpy()\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(confusion_matrix(all_labels, all_preds) ,xticklabels=['regular', 'pneumonia', 'covid'], yticklabels=['regular', 'pneumonia', 'covid'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "#references: https://seaborn.pydata.org/generated/seaborn.heatmap.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "162cebb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "162cebb6",
        "outputId": "7752cfaf-054d-416d-d1b5-d986e2deccd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([28, 512, 28, 28])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.027299487305258562, 0.7694610778443114)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# testing\n",
        "test_accuracy = eval_one_epoch(testloader, net, criterion)\n",
        "test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bFeFuIjV8Wxa",
      "metadata": {
        "id": "bFeFuIjV8Wxa"
      },
      "outputs": [],
      "source": [
        "class COVIDNetCustom(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(COVIDNetCustom, self).__init__()\n",
        "        self.features = nn.Sequential(nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),nn.BatchNorm2d(32),nn.ReLU(),nn.MaxPool2d(2, 2),nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(64),nn.ReLU(),nn.MaxPool2d(2, 2),nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(128),nn.ReLU(),nn.MaxPool2d(2, 2),nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(256),nn.ReLU(),nn.AdaptiveAvgPool2d((1, 1)))\n",
        "        self.classifier = nn.Sequential(nn.Linear(256, 128),nn.ReLU(),nn.Dropout(0.3),nn.Linear(128, num_classes))\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x.view(x.size(0), -1))\n",
        "#reference: https://github.com/dragonbook/cs231n-assignments/blob/master/assignment2/my/models.py\n",
        "#reference: https://medium.com/analytics-vidhya/cnn-with-custom-dataset-8cdd153f5c9e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "xhuxXsekDyu-",
      "metadata": {
        "id": "xhuxXsekDyu-"
      },
      "outputs": [],
      "source": [
        "custom_params = {'lr': 1e-3,'batch_size': 32,'epochs': 30,'patience': 5}\n",
        "custom_net = COVIDNetCustom().to(device)\n",
        "custom_optimizer = optim.Adam(custom_net.parameters(), lr=custom_params['lr'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(custom_optimizer, 'min', patience=2)\n",
        "#reference: https://github.com/Nixtla/neuralforecast/issues/1096\n",
        "#reference: https://medium.com/data-scientists-diary/guide-to-pytorch-learning-rate-scheduling-b5d2a42f56d4\n",
        "#reference: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/Basics/pytorch_lr_ratescheduler.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "gnvlalIbD1eM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnvlalIbD1eM",
        "outputId": "4a97050a-9cb6-467b-a9d7-2c6862153334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 1 Time: 20.45443630218506 Val Loss: 0.027893596623247443 Val Acc: 0.7024320457796852\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 2 Time: 19.65399694442749 Val Loss: 0.027081397043618352 Val Acc: 0.7939914163090128\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 3 Time: 20.03672742843628 Val Loss: 0.0270149614848463 Val Acc: 0.7696709585121603\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 4 Time: 19.932204484939575 Val Loss: 0.02674385883947981 Val Acc: 0.8011444921316166\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 5 Time: 19.792993783950806 Val Loss: 0.02686018954019178 Val Acc: 0.7854077253218884\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 6 Time: 19.928515911102295 Val Loss: 0.02675855773712944 Val Acc: 0.7911301859799714\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 7 Time: 19.78295612335205 Val Loss: 0.027643066278001952 Val Acc: 0.759656652360515\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 8 Time: 19.66947364807129 Val Loss: 0.026897002528494862 Val Acc: 0.7954220314735336\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([16, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 9 Time: 19.73069667816162 Val Loss: 0.028036111584719327 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 1 Time: 4.151090621948242 Val Loss: 0.02806610909313262 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 2 Time: 3.984990358352661 Val Loss: 0.028057660241324844 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 3 Time: 3.987020254135132 Val Loss: 0.028041638188778247 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 4 Time: 3.9743688106536865 Val Loss: 0.028041916599601122 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 5 Time: 3.978703022003174 Val Loss: 0.028036673778457533 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 6 Time: 3.9819791316986084 Val Loss: 0.02802359904342455 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 7 Time: 3.979301691055298 Val Loss: 0.028042862770042365 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 8 Time: 4.005374431610107 Val Loss: 0.028034503367837405 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 9 Time: 3.9849908351898193 Val Loss: 0.02805534623382088 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 10 Time: 3.9628167152404785 Val Loss: 0.0280276994848456 Val Acc: 0.7353361945636624\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([27, 512, 28, 28])\n",
            "Epoch: 11 Time: 3.986227035522461 Val Loss: 0.02804975482356736 Val Acc: 0.7353361945636624\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "def train_model(model, optimizer, criterion, trainloader, valloader, epochs, patience):\n",
        "    best_loss = float('inf')\n",
        "    no_improve = 0\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time() #timing\n",
        "        model.train()\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        val_loss, val_acc = eval_one_epoch(valloader, model, criterion)\n",
        "        scheduler.step(val_loss)\n",
        "        epoch_time = time.time() - epoch_start #timing\n",
        "        # Early stopping\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_custom_model.pth')\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "        print(\"Epoch:\", epoch+1, \"Time:\",epoch_time, \"Val Loss:\", val_loss, \"Val Acc:\",val_acc)\n",
        "        if no_improve >= patience:\n",
        "            break\n",
        "    total_time = time.time() - start_time\n",
        "    return total_time\n",
        "\n",
        "# Train both models\n",
        "vgg_time, custom_time  = train_model(net, optimizer, criterion, trainloader, valloader, epochs, patience), train_model(custom_net, custom_optimizer, criterion,trainloader, valloader,custom_params['epochs'], custom_params['patience'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "jPum7i0XD4Xw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPum7i0XD4Xw",
        "outputId": "8567517b-8778-4e57-8fc7-365f363dc7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([28, 512, 28, 28])\n",
            "\n",
            "Model           Accuracy   Training Time   \n",
            "VGG-16          0.7695      250.9s \n",
            "Custom CNN      0.6257      44.1s\n"
          ]
        }
      ],
      "source": [
        "net.load_state_dict(torch.load('best_model.pth'))\n",
        "custom_net.load_state_dict(torch.load('best_custom_model.pth'))\n",
        "def full_eval(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        all_correct = 0\n",
        "        for images, labels in testloader:\n",
        "            outputs = model(images.to(device))\n",
        "            preds = outputs.argmax(1).cpu()\n",
        "            all_correct += np.sum(preds.numpy() == labels.numpy())\n",
        "        return all_correct / len(testloader.dataset)\n",
        "vgg_acc, custom_acc = full_eval(net, testloader), full_eval(custom_net, testloader)\n",
        "# Results comparison (fancier than other printing LOL)\n",
        "print(f\"\\n{'Model':<15} {'Accuracy':<10} {'Training Time':<15} \\n{'VGG-16':<15} {vgg_acc:.4f}{'':<5} {vgg_time:.1f}s \\n{'Custom CNN':<15} {custom_acc:.4f}{'':<5} {custom_time:.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be22bce",
      "metadata": {
        "id": "9be22bce"
      },
      "source": [
        "Custom CNN is much faster than the VGG-16, although a slight dip in accuracy but it is a huge time savings,as shown above."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
